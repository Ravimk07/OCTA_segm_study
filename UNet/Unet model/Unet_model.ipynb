{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation\n",
    "from keras.layers.advanced_activations import ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(x)\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
    "    p = keras.layers.MaxPool2D((2, 2), (2, 2))(c)\n",
    "    return c, p\n",
    "\n",
    "def up_block(x, skip, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    us = keras.layers.UpSampling2D((2, 2))(x)\n",
    "    concat = keras.layers.Concatenate()([us, skip])\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(concat)\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
    "    return c\n",
    "\n",
    "def bottleneck(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(x)\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def UNet():\n",
    "    f = [32, 64, 128]\n",
    "    inputs = keras.layers.Input((image_size, image_size, 1))\n",
    "    \n",
    "    p0 = inputs\n",
    "    c1, p1 = down_block(p0, f[0])\n",
    "    c2, p2 = down_block(p1, f[1]) \n",
    "    \n",
    "    \n",
    "    bn = bottleneck(p2, f[2])\n",
    "    \n",
    "    u1 = up_block(bn, c2, f[1]) \n",
    "    u2 = up_block(u1, c1, f[0])\n",
    "    \n",
    "    outputs = keras.layers.Conv2D(1, (1, 1), padding=\"same\", activation=\"sigmoid\")(u2)\n",
    "    model = keras.models.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 32\n",
    "model = UNet()\n",
    "model.compile(optimizer=\"SGD\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment the images\n",
    "# Notice that training, lab_training, validation, lav_validation are folders which contain another folder with the same name\n",
    "# for more information see https://keras.io/preprocessing/image/\n",
    "seed = 1\n",
    "data_gen_args = dict(\n",
    "                     rescale = 1./255, \n",
    "                     vertical_flip = True,\n",
    "                     horizontal_flip=True)\n",
    "\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "flow_from_dir_params = dict(target_size = (32,32), class_mode=None,shuffle=False, seed=seed, color_mode = 'grayscale', batch_size=32)\n",
    "\n",
    "image_generator = image_datagen.flow_from_directory('./training_all', **flow_from_dir_params)\n",
    "\n",
    "mask_generator = mask_datagen.flow_from_directory('./lab_training_all/', **flow_from_dir_params)\n",
    "val_generator = image_datagen.flow_from_directory('./validation', **flow_from_dir_params)\n",
    "\n",
    "val_mask_generator = mask_datagen.flow_from_directory('./lab_validation', **flow_from_dir_params)\n",
    "\n",
    "# combine generators\n",
    "train_generator = zip(image_generator, mask_generator)\n",
    "valid_generator = zip(val_generator, val_mask_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_train_val = model.fit_generator(generator=train_generator,validation_data=valid_generator,  epochs = 13, steps_per_epoch=800, validation_steps= 100, use_multiprocessing=False, max_queue_size=10, workers=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = model_train_val.history['acc']\n",
    "val_accuracy = model_train_val.history['val_acc']\n",
    "loss = model_train_val.history['loss']\n",
    "val_loss = model_train_val.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'C1', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('acc.png')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'C1', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "#plt.show()\n",
    "plt.savefig('loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "from keras.models import model_from_json\n",
    "from keras.models import load_model\n",
    "\n",
    "model_json = model_train_val.model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "model_train_val.model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
